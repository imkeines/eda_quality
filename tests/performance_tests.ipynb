{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T14:13:39.774135Z",
     "start_time": "2020-11-10T14:13:38.438068Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "\n",
    "# load dependencies'\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from math import ceil, floor\n",
    "from shapely.geometry import Polygon, MultiPoint\n",
    "import datetime\n",
    "\n",
    "from envirocar import TrackAPI, DownloadClient, BboxSelector, ECConfig#, TrackConverter\n",
    "from eda_quality import inspection as inspect\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore')#, category=FutureWarning)\n",
    "\n",
    "\n",
    "# create an initial but optional config and an api client\n",
    "config = ECConfig()\n",
    "track_api = TrackAPI(api_client=DownloadClient(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T14:13:46.653725Z",
     "start_time": "2020-11-10T14:13:39.775826Z"
    }
   },
   "outputs": [],
   "source": [
    "bbox =BboxSelector([\n",
    "    7.004130554199218, # min_x\n",
    "    52.50590322041212, # min_y\n",
    "    7.990351104736328, # max_x\n",
    "    52.99874790276371  # max_y\n",
    "])\n",
    "\n",
    "\n",
    "# issue a query\n",
    "track_df = track_api.get_tracks(bbox=bbox, num_results=2) # requesting 10 tracks inside the bbox\n",
    "# track_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T14:13:46.707601Z",
     "start_time": "2020-11-10T14:13:46.655393Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    }
   ],
   "source": [
    "\n",
    "%prun \n",
    "\n",
    "def spatioTemporalAggregation(df, field, summary, gridSize):\n",
    "    \"\"\"\n",
    "    Aggregates the given field on hour and weekday basis.\n",
    "    Prepares data for mosaic plot\n",
    "    FOR THIS TO WORK YOU NEED TO INSTALL RTree or Rtree-linux!!!\n",
    "    # TODO This function is poorly performing\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : geopandas dataframe\n",
    "    field : string\n",
    "        field to be summarized.\n",
    "    summary : string\n",
    "        type of summary to be sumarized. eg. min, max,sum, median\n",
    "    gridSize : float\n",
    "        the size of grid on same unit as geodataframe coordinates.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    geodataframes: one each for larger grid and other for subgrids\n",
    "        (for visualization purpose only)\n",
    "        Aggregated grids with summary on it\n",
    "\n",
    "    \"\"\"\n",
    "    def round_down(num, divisor):\n",
    "        return floor(num / divisor) * divisor\n",
    "\n",
    "    def round_up(num, divisor):\n",
    "        return ceil(num / divisor) * divisor\n",
    "\n",
    "    # Get crs from data\n",
    "    sourceCRS = df.crs\n",
    "    targetCRS = \"epsg:3857\"\n",
    "    # Reproject to Mercator\\\n",
    "    df = df.to_crs(targetCRS)\n",
    "\n",
    "    # Get bounds\n",
    "    xmin, ymin, xmax, ymax = df.total_bounds\n",
    "    height, width = gridSize, gridSize\n",
    "    top, left = round_up(ymax, height), round_down(xmin, width)\n",
    "    bottom, right = round_down(ymin, height), round_up(xmax, width)\n",
    "\n",
    "    rows = int((top - bottom) / height)+1\n",
    "    cols = int((right - left) / width)+1\n",
    "\n",
    "    XleftOrigin = left\n",
    "    XrightOrigin = left + width\n",
    "    YtopOrigin = top\n",
    "    YbottomOrigin = top - height\n",
    "    polygons = []\n",
    "\n",
    "    for i in range(cols):\n",
    "        Ytop = YtopOrigin\n",
    "        Ybottom = YbottomOrigin\n",
    "        for j in range(rows):\n",
    "            polygons.append(Polygon(\n",
    "                [(XleftOrigin, Ytop), (XrightOrigin, Ytop),\n",
    "                 (XrightOrigin, Ybottom), (XleftOrigin, Ybottom)]))\n",
    "            Ytop = Ytop - height\n",
    "            Ybottom = Ybottom - height\n",
    "        XleftOrigin = XleftOrigin + width\n",
    "        XrightOrigin = XrightOrigin + width\n",
    "\n",
    "    grid = gpd.GeoDataFrame({'geometry': polygons})\n",
    "    grid.crs = (targetCRS)\n",
    "\n",
    "    # Assign gridid\n",
    "    numGrid = len(grid)\n",
    "    grid['gridId'] = list(range(numGrid))\n",
    "\n",
    "    # Identify gridId for each point\n",
    "\n",
    "    df['hour'] = df['time'].apply(\n",
    "        lambda x: datetime.datetime.strptime(\n",
    "            x, '%Y-%m-%dT%H:%M:%S+00:00')).dt.hour\n",
    "    df['weekday'] = df['time'].apply(\n",
    "        lambda x: datetime.datetime.strptime(\n",
    "            x, '%Y-%m-%dT%H:%M:%S+00:00')).dt.dayofweek\n",
    "\n",
    "    # df['hour'] = pd.to_datetime(df['time']).dt.hour\n",
    "    # df['weekday'] = pd.to_datetime(df['time']).dt.dayofweek\n",
    "\n",
    "    points_identified = gpd.sjoin(df, grid, op='within')\n",
    "\n",
    "    # group points by gridid and calculate mean Easting,\n",
    "    # store it as dataframe\n",
    "    # delete if field already exists\n",
    "    if field in grid.columns:\n",
    "        del grid[field]\n",
    "\n",
    "    # Aggregate by weekday, hour and grid\n",
    "    grouped = points_identified.groupby(\n",
    "        ['gridId', 'weekday', 'hour']).agg({field: [summary]})\n",
    "    grouped = grouped.reset_index()\n",
    "    grouped.columns = grouped.columns.map(\"_\".join)\n",
    "    modified_fieldname = field+\"_\"+summary\n",
    "\n",
    "    # Create Subgrids\n",
    "    subgrid, mainGrid, rowNum, columnNum, value = [], [], [], [], []\n",
    "    unikGrid = grouped['gridId_'].unique()\n",
    "    print('running; wait till you see \"finished\"')\n",
    "    for currentGrid in unikGrid:\n",
    "        dataframe = grid[grid['gridId'] == currentGrid]\n",
    "        xmin, ymin, xmax, ymax = dataframe.total_bounds\n",
    "        xminn, xmaxx, yminn, ymaxx = xmin + \\\n",
    "            (xmax-xmin)*0.05, xmax-(xmax-xmin)*0.05, ymin + \\\n",
    "            (ymax-ymin)*0.05, ymax-(ymax-ymin)*0.05\n",
    "        rowOffset = (ymaxx-yminn)/24.0\n",
    "        colOffset = (xmaxx - xminn)/7.0\n",
    "        tmp = (grouped['gridId_'] == currentGrid)\n",
    "        for i in range(7):\n",
    "            tmp2=(grouped['weekday_'] == i)\n",
    "            for j in range(24):\n",
    "                topy, bottomy, leftx, rightx = ymaxx-j*rowOffset, ymaxx - \\\n",
    "                    (j+1)*rowOffset, xminn+i * \\\n",
    "                    colOffset, xminn+(i+1)*colOffset\n",
    "                subgrid.append(\n",
    "                    Polygon([(leftx, topy), (rightx, topy),\n",
    "                             (rightx, bottomy), (leftx, bottomy)]))\n",
    "                mainGrid.append(currentGrid)\n",
    "                rowNum.append(j)\n",
    "                columnNum.append(i)\n",
    "                if len(grouped[tmp\n",
    "                       & tmp2\n",
    "                       & (grouped['hour_'] == j)]) != 0:\n",
    "                    this_value = grouped[\n",
    "                        tmp\n",
    "                        & tmp2\n",
    "                        & (grouped['hour_'] == j)].iloc[0][\n",
    "                            modified_fieldname]\n",
    "                    value.append(this_value)\n",
    "                else:\n",
    "                    value.append(np.nan)\n",
    "    subgrid_gpd = gpd.GeoDataFrame({'geometry': subgrid})\n",
    "    subgrid_gpd.crs = targetCRS\n",
    "    # Reproject to Mercator\\\n",
    "    subgrid_gpd = subgrid_gpd.to_crs(sourceCRS)\n",
    "    subgrid_gpd['gridId'] = mainGrid\n",
    "    subgrid_gpd['Weekday'] = columnNum\n",
    "    subgrid_gpd['hour'] = rowNum\n",
    "    subgrid_gpd['gridId'] = subgrid_gpd.apply(lambda x: str(\n",
    "        x['gridId'])+\"_\"+str(x['Weekday'])+\"_\"+str(x['hour']), axis=1)\n",
    "    subgrid_gpd[modified_fieldname] = value\n",
    "    subgrid_gpd = subgrid_gpd.dropna()\n",
    "    grid = grid.to_crs(sourceCRS)\n",
    "    grid = grid[grid['gridId'].isin(unikGrid)]\n",
    "    print('finished')\n",
    "    return grid, subgrid_gpd\n",
    "    # final_subgrid=subgrid_gpd[subgrid_gpd['value'].notnull()]\n",
    "    # return final_subgrid\n",
    "\n",
    "#%prun spatioTemporalAggregation(track_df, \"Speed.value\",\"mean\",1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Script Profile\n",
    "Here we determine the performance of the function 'spatioTemporalAggregation' from the module 'Inspection' with python's built-in code profiler. This will open the pager (a window) with a table the indicates where the execution is spending the most time on order of total time on each function call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T14:15:28.153930Z",
     "start_time": "2020-11-10T14:13:46.709013Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running; wait till you see \"finished\"\n",
      "finished\n",
      " "
     ]
    }
   ],
   "source": [
    "%prun spatioTemporalAggregation(track_df, \"Speed.value\",\"mean\",1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Line-by-Line Profile\n",
    "With the package line_profiler we can get a line-by-line report, instead of a function-by-function report. For this install the line_profiler with pip and load the line-profiler extension. You need to explicitly define which function you are interested in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T14:17:45.733606Z",
     "start_time": "2020-11-10T14:15:28.156878Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running; wait till you see \"finished\"\n",
      "finished\n"
     ]
    }
   ],
   "source": [
    "%load_ext line_profiler\n",
    "\n",
    "%lprun -f spatioTemporalAggregation spatioTemporalAggregation(track_df, \"Speed.value\",\"mean\",1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envirocar_preprocessing",
   "language": "python",
   "name": "envirocar_preprocessing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
