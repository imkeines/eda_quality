{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'envirocar.EDA'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-7c62809e7135>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0menvirocar\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTrackAPI\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDownloadClient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBboxSelector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mECConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mInspection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;31m# create an initial but optional config and an api client\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mECConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/CITRAM/enviroCar_fork/envirocar_preprocessing/lib/python3.7/site-packages/envirocar/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest_param\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBboxSelector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTimeSelector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mEDA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minspection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInspection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'envirocar.EDA'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# pandas show all columns of table instead of restricted#\n",
    "pd.set_option('display.max_columns', None)\n",
    "import geopandas as gpd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# set path to import local envirocar module\n",
    "import sys\n",
    "import os\n",
    "#sys.path.append('..')\n",
    "\n",
    "\n",
    "from envirocar import TrackAPI, DownloadClient, BboxSelector, ECConfig, Inspection\n",
    "# create an initial but optional config and an api client\n",
    "config = ECConfig()\n",
    "track_api = TrackAPI(api_client=DownloadClient(config=config))\n",
    "#inspect=Inspection()\n",
    "#from .EDA.inspection import Inspection\n",
    "\n",
    "def get_coordinates(df):\n",
    "        df['lat'] = df['geometry'].apply(lambda coord: coord.y)\n",
    "        df['lng'] = df['geometry'].apply(lambda coord: coord.x)\n",
    "        \n",
    "\n",
    "def get_units(df):\n",
    "    '''\n",
    "        Aim: \n",
    "            get an overview of the variables and corresponding units\n",
    "        \n",
    "        Keyword Arguments: \n",
    "            df {Geodataframe} -- point input\n",
    "        \n",
    "        Output: Matrix-like overview on variables an the relevant unit\n",
    "    '''\n",
    "    units = df.filter(like='.unit').columns\n",
    "    unitList=[]\n",
    "    for unit in units:\n",
    "        if unit in df:\n",
    "            unitList.append(unit)\n",
    "            print(df[unit].name, df[unit].iloc[0])\n",
    "    return(unitList)\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox = BboxSelector([\n",
    "    7.554130554199218, # min_x\n",
    "    51.95590322041212, # min_y\n",
    "    7.590351104736328, # max_x\n",
    "    51.97874790276371  # max_y\n",
    "])\n",
    "\n",
    "# issue a query\n",
    "track_df = track_api.get_tracks(bbox=bbox, num_results=40) \n",
    "track_df.drop_duplicates(subset=['geometry', 'Engine Load.value', 'Calculated MAF.value',\n",
    "       'Speed.value', 'CO2.value', 'Intake Pressure.value', 'Rpm.value',\n",
    "       'Intake Temperature.value', 'Consumption (GPS-based).value',\n",
    "       'GPS Altitude.value', 'Throttle Position.value', 'GPS Bearing.value',\n",
    "       'Consumption.value', 'GPS Accuracy.value',\n",
    "       'CO2 Emission (GPS-based).value', 'GPS Speed.value', \n",
    "       'track.length', 'track.begin', 'track.end', 'sensor.type',\n",
    "       'sensor.engineDisplacement', 'sensor.model', 'sensor.id',\n",
    "       'sensor.fuelType', 'sensor.constructionYear', 'sensor.manufacturer',\n",
    "       'track.appVersion', 'track.touVersion', 'GPS HDOP.value',\n",
    "       'GPS PDOP.value', 'GPS VDOP.value'], inplace=True, keep='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get subset of numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_df_numeric=track_df.select_dtypes('float64')\n",
    "track_df_numeric.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_df['index']=track_df.index\n",
    "track_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspect categorical vairables\n",
    "As we want to create dummy varaibles for the categorical variables, we will first inspect each categorical\n",
    "variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_df['sensor.manufacturer'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_df['sensor.fuelType'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_df['sensor.model'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple Preprocessing for only numerical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take only numerical variables\n",
    "track_df_numeric = track_df.select_dtypes(['float64']).copy()\n",
    "track_df_numeric['index']=track_df_numeric.index\n",
    "track_df_numeric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing pipeline for complete dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create our preprocessing pipeline and apply it on the dataframe.\n",
    "Here we do a simple median imputation and apply feature scaling in our pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_numerical = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('std_scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# this returns a numpy array\n",
    "tracksPiped=pipeline_numerical.fit_transform(track_df_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy array to pandas dataframe\n",
    "tracksPiped = pd.DataFrame(tracksPiped, columns=track_df_numeric.columns, index=track_df_numeric['index'])\n",
    "tracksPiped.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing pipeline columnwise\n",
    "Here we apply processes on specific columns in a datraframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create lists of colums per datatype or for which you like to  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes_numerical=list(track_df_numeric)\n",
    "attributes_categorical=['sensor.fuelType','sensor.manufacturer', 'sensor.model']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create pipeline columnwise.\n",
    "Here we 'reuse' the pipeline from above for the numerical variables. However, on the categorical variables\n",
    "we apply the OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_full = ColumnTransformer([\n",
    "    (\"num\", pipeline_numerical, attributes_numerical),\n",
    "    (\"cat\", OneHotEncoder(), attributes_categorical),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply pipeline on dataframe\n",
    "This will return a n-d numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processedColumnwise = pipeline_full.fit_transform(track_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DF creation of numpy array\n",
    "To create a dataframe from the array we need a list of appropriate names for the columns. Therefore we first create lists from the names of the categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fuelTypeList=list(map('sensor.fuelType_'.__add__,track_df['sensor.fuelType'].unique().tolist()))\n",
    "manuList=list(map('sensor.manufacturer_'.__add__,track_df['sensor.manufacturer'].unique().tolist()))\n",
    "modelList=list(map('sensor.model_'.__add__,track_df['sensor.model'].unique().tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create complete column list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns1=attributes_numerical+fuelTypeList+manuList+modelList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dataframe from array and controle per eye if data and columns are correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processedColumnwise= pd.DataFrame(processedColumnwise, columns=columns1, index=track_df.index)\n",
    "processedColumnwise.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create custom transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flag_outlier_in_sample(df, listOfVariableNames, dropOutlierColumn=False, setOutlierToNan=False):\n",
    "    '''\n",
    "        Aim: Find outlier with regard to the sample's distribution \n",
    "        \n",
    "        Input: Geodataframa\n",
    "        \n",
    "        Output: Geodataframe with added column which values are '1' \n",
    "                when a certain value of a variable in the list is considered to be an outlier regarding the samples's distribution\n",
    "    '''\n",
    "    df['outlier_in_sample'] = 0\n",
    "    for variable in listOfVariableNames:\n",
    "        variableName='outlier_in_sample_'+ variable\n",
    "        df[variableName] = 0\n",
    "        Q1 = df[variable].quantile(0.25)\n",
    "        Q3 = df[variable].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        low_lim = Q1 - 1.5 * IQR \n",
    "        up_lim = Q3 + 1.5 * IQR  \n",
    "        df.loc[df[variable] < low_lim, variableName] = 1\n",
    "        df.loc[df[variable] > up_lim, variableName] = 1\n",
    "        df.loc[df[variable] < low_lim, 'outlier_in_sample'] = 1\n",
    "        df.loc[df[variable] > up_lim, 'outlier_in_sample'] = 1\n",
    "        print(variableName, (df[variableName].values == 1).sum())\n",
    "        \n",
    "        if setOutlierToNan == True:\n",
    "            df.loc[df[variableName] == 1 , variable] = np.nan\n",
    "        \n",
    "        if dropOutlierColumn == True:\n",
    "            df.drop([variableName], axis=1, inplace=True)\n",
    "            \n",
    "    outlier = (df['outlier_in_sample'].values == 1).sum()\n",
    "    print('Flagged outlier in sample: ', outlier)\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_coordinates(df):\n",
    "        df['lat'] = df['geometry'].apply(lambda coord: coord.y)\n",
    "        df['lng'] = df['geometry'].apply(lambda coord: coord.x)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetCoordinates(BaseEstimator, TransformerMixin):\n",
    "    def _init_(self, get_coordinates=True):\n",
    "        self.get_coordinates=get_coordinates\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        lat = X[geometry].apply(lambda coord: coord.x)\n",
    "        if self.get_coordinates:\n",
    "            return np.c_[X, lat]\n",
    "        else:\n",
    "            return np.c_[X]\n",
    "        \n",
    "    #coord_add=GetCoordinates(get_coordinates=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes_geom=['geometry']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelinie=ColumnTransformer([\n",
    "    ('geom', GetCoordinates, attributes_geom),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processedGeo = pipelinie.fit_transform(track_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envirocar_preprocessing",
   "language": "python",
   "name": "envirocar_preprocessing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
